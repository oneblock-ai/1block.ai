"use strict";(self.webpackChunk_1_block_ai=self.webpackChunk_1_block_ai||[]).push([[4031],{4108:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"introducing-llmos-v02","metadata":{"permalink":"/blog/introducing-llmos-v02","editUrl":"https://github.com/oneblock-ai/1block.ai/tree/main/blog/llmos-0.2-release.mdx","source":"@site/blog/llmos-0.2-release.mdx","title":"LLMOS v0.2 - Simplify AI Management, Unlock GPU Potential","description":"\ud83d\ude80 Introducing LLMOS v0.2","date":"2024-12-31T00:00:00.000Z","tags":[{"inline":true,"label":"1Block.AI","permalink":"/blog/tags/1-block-ai"},{"inline":true,"label":"AI Infrastructure","permalink":"/blog/tags/ai-infrastructure"}],"readingTime":2.765,"hasTruncateMarker":false,"authors":[{"name":"Guangbo Chen","title":"Founder of 1BLOCK.AI","url":"https://github.com/guangbochen","email":"guangbo@1block.ai","socials":{"github":"https://github.com/guangbochen","linkedin":"https://www.linkedin.com/in/guangbo/"},"imageURL":"https://github.com/guangbochen.png","key":"guangbo","page":null}],"frontMatter":{"slug":"introducing-llmos-v02","title":"LLMOS v0.2 - Simplify AI Management, Unlock GPU Potential","tags":["1Block.AI","AI Infrastructure"],"authors":["guangbo"],"date":"2024-12-31T00:00:00.000Z","hide_table_of_contents":false},"unlisted":false,"nextItem":{"title":"Introducing LLMOS","permalink":"/blog/introducing-llmos"}},"content":"## **\ud83d\ude80 Introducing LLMOS v0.2**\\n\\n**LLMOS** is a cloud-native tool designed to **accelerate AI application development** and **simplify the management of large language models (LLMs)**. It supports deployment on both **public clouds** and **private GPU servers**, enabling you to easily deploy private AI models, scale machine learning workflows, and reduce the complexity of development and operations.\\n\\nWith the increasing demand for GPU virtualization (vGPU) and resource utilization, the **v0.2** release prioritizes features like **vGPU management**, **cluster and GPU resource monitoring**, and **alerting** to maximize GPU management efficiency and utilization.\\n\\n## **\ud83c\udf1f Key Features**\\n\\n### **1. More Efficient GPU Management**\\n\\nIntroducing support for **NVIDIA Virtual GPU (vGPU)**, allowing you to choose between virtual or full GPUs based on your needs. This accelerates resource allocation and optimizes the utilization of GPU VRAM and CUDA cores.\\n\\n| GPU Model | Support | Architecture |\\n| --- | --- | --- |\\n| A100, A200 | \u2705 | NVIDIA Ampere |\\n| H100, H200 | \u2705 | NVIDIA Hopper |\\n| Tesla T4/T4G | \u2705 | NVIDIA Turing |\\n| 30x/40x Series | \u2705 | Ada Lovelace/Ampere |\\n\\n\u2714 **Virtual GPU (vGPU)**: Optimize GPU utilization and scale workloads seamlessly.\\n\\n![model-service-create](llmos-release-02/model-service-create.png)\\n![model-service-vram](llmos-release-02/model-service-vram.png)\\n\\n\u2714 **GPU Management Interface**: Intuitively view GPU details and monitor resources in real time.\\n\\n![gpu-device](llmos-release-02/gpu-device.png)\\n![gpu-device-metrics](llmos-release-02/gpu-device-metrics.png)\\n\\n\ud83d\udc49 [Learn More](https://llmos.1block.ai/docs/user_guide/gpu_management/enable-gpu-stack/)\\n\\n### **2. Real-Time Monitoring and Alerts**\\n\\nEnable GPU and cluster monitoring with a single click using preconfigured **Grafana dashboards and Prometheus alerts**. Track performance metrics in real time to ensure stable workload operations.\\n\\n\u2714 **Real-Time Monitoring**: Stay informed about cluster and GPU status.\\n\\n![cluster-gpu-metrics](llmos-release-02/cluster-gpu-metrics.png)\\n\\n\u2714 **Intelligent Alerts**: Predefined rules to reduce risks of failures and downtime.\\n\\n![monitoring-rules](llmos-release-02/monitoring-rules.png)\\n\\n\u2714 **Pause and Resume Workloads**: Release idle resources to enhance efficiency.\\n\\n![workload-actions](llmos-release-02/workload-actions.png)\\n\\n\ud83d\udc49 [Learn More](https://llmos.1block.ai/docs/user_guide/monitoring/monitoring-management/)\\n\\n## **\u26a1 Key Enhancements**\\n\\n### **1. Faster Installation Experience**\\n\\n- For CN users, you can accelerate installation with `--mirror cn`.\\n  ```bash\\n  curl -sfL https://get-llmos.1block.ai | sh -s - --cluster-init --token mytoken --mirror cn\\n  ```\\n\\n- For restricted network and air-gap environments, use configurations like `globalSystemImageRegistry` or `registries` to integrate private image registries, accelerating and simplifying the installation process.\\n\\n\\n### **2. Expanded Model Service Sources**\\n\\nSupport loading AI models from [HuggingFace](https://huggingface.co/models), [ModelScope](https://modelscope.cn/models), or local paths, offering more flexibility in model deployment for your projects.\\n\\n![model-service-sources](llmos-release-02/model-service-sources.png)\\n\\n\\n\\n### **3. Optimized Workload Management**\\n- **Automatic Volume Cleanup**: Automatically release storage resources after workload deletion, simplifying management.\\n- **Notebook Optimization**: Added support for Jupyter Pipeline images and i18n localization(e.g., Chinese) patches.\\n  ![notebook-pipeline](llmos-release-02/notebook-pipeline.png)\\n- **Node-Level GPU Metrics Optimization**: Gain detailed overviews of GPU resources to enable fine-grained management.\\n  ![node-metrics](llmos-release-02/node-metrics.png)\\n- **Enhanced Model Token Metrics**: View real-time model token usage and response speeds to optimize resource planning and task execution of model services.\\n  ![token-metrics](llmos-release-02/token-metrics.png)\\n\\n---\\n\\n## **\ud83d\udee0 Updates and Fixes**\\n\\n- **Dependency Updates**: System dependencies have been updated to improve performance, security, and compatibility:\\n  - Rook Ceph and Ceph cluster upgraded to `v1.15.7`.\\n  - Snapshot Controller upgraded to `v8.2.0`.\\n  - Upgrade Controller upgraded to `v0.14.2`.\\n- **Key Bug Fixes**:\\n  - **Model Service Parameter Issues**: Fixed to allow seamless parameter updates.\\n  - **Label Nil Exception**: Custom addon will no longer experience label `nil` exception.\\n  - **User Permission Optimization**: Removed unnecessary node permissions for regular users, enhancing security.\\n\\n\\n## **\ud83c\udf10 Ready to Experience?**\\n\\nVisit the [documentation](https://llmos.1block.ai/docs/) to learn more. Upgrade to LLMOS v0.2 today and experience the future of AI management!\\n\\n\ud83d\ude80 **Upgrade Now!**"},{"id":"introducing-llmos","metadata":{"permalink":"/blog/introducing-llmos","editUrl":"https://github.com/oneblock-ai/1block.ai/tree/main/blog/introduce-llmos-0.1.0.mdx","source":"@site/blog/introduce-llmos-0.1.0.mdx","title":"Introducing LLMOS","description":"An Open-source Cloud-native AI Infrastructure Platform, Not Just GPUs","date":"2024-10-17T00:00:00.000Z","tags":[{"inline":true,"label":"1Block.AI","permalink":"/blog/tags/1-block-ai"},{"inline":true,"label":"AI Infrastructure","permalink":"/blog/tags/ai-infrastructure"}],"readingTime":4.5,"hasTruncateMarker":false,"authors":[{"name":"Guangbo Chen","title":"Founder of 1BLOCK.AI","url":"https://github.com/guangbochen","email":"guangbo@1block.ai","socials":{"github":"https://github.com/guangbochen","linkedin":"https://www.linkedin.com/in/guangbo/"},"imageURL":"https://github.com/guangbochen.png","key":"guangbo","page":null}],"frontMatter":{"slug":"introducing-llmos","title":"Introducing LLMOS","tags":["1Block.AI","AI Infrastructure"],"authors":["guangbo"],"date":"2024-10-17T00:00:00.000Z","hide_table_of_contents":false},"unlisted":false,"prevItem":{"title":"LLMOS v0.2 - Simplify AI Management, Unlock GPU Potential","permalink":"/blog/introducing-llmos-v02"},"nextItem":{"title":"Hello World @1Block.AI","permalink":"/blog/welcome"}},"content":"## An Open-source Cloud-native AI Infrastructure Platform, Not Just GPUs\\n\\n## What is LLMOS?\\n\\nWe are thrilled to announce the launch of **LLMOS**, an open-source cloud-native AI infrastructure platform designed to simplify the management of AI applications and Large Language Models (LLMs). With LLMOS, organizations can effortlessly deploy, scale, and operate machine learning workflows while reducing the complexity often associated with AI development and operations.\\n\\n## Why We Built LLMOS\\n\\nAI and LLMs are transforming industries, but managing the infrastructure needed for AI at scale can be challenging. We built **LLMOS** to break down these barriers, providing a platform that makes it easier for developers, data scientists, and IT teams to focus on what really matters\u2014building and deploying powerful AI solutions. With its cloud-native foundation, LLMOS integrates smoothly with existing infrastructure, offering a flexible, scalable, and user-friendly way to manage AI projects and tasks.\\n\\n## Key Features of LLMOS\\n\\n### 1. Seamless Notebook Integration\\n\\nLLMOS integrates with popular notebook environments such as **Jupyter**, **VSCode**, and **RStudio**, enabling data scientists and developers to work efficiently in familiar tools without complicated setup.\\n\\n![jupyter-notebook](introduce-llmos/jupyter-notebook.png)\\n\\n### 2. ModelService for LLM Deployment\\n\\nDeploying LLMs is now simpler with **ModelService**, which provides **OpenAI-compatible APIs** for serving large language models. This feature makes it easy to deploy, scale, and use LLMs in real-world applications.\\n\\n![model-service](introduce-llmos/model-service.png)\\n\\n### 3. Machine Learning Cluster\\n\\nThe **Machine Learning Cluster** supports distributed computing, offering parallel processing and access to leading AI libraries. This feature enhances the performance of machine learning workflows, especially for large-scale models and datasets.\\n\\n![machine-learning-cluster](introduce-llmos/ml-cluster.png)\\n\\n### 4. Scalable Storage with Rook Ceph\\n\\n**Rook Ceph** provides distributed and fault-tolerant storage system for LLMOS, offering robust, scalable block and filesystem storage that adapts to the needs of AI and LLM applications.\\n\\n![roo-ceph](introduce-llmos/rook-ceph.png)\\n\\n### 5. Extensibility with Managed Addons\\n\\nLLMOS introduces **ManagedAddon** support, allowing users to extend the platform with system and custom add-ons. This gives organizations more flexibility to tailor the platform to their specific needs.\\n\\n### 6. Simplified User and API Key Management\\n\\nThe platform features an intuitive interface for managing **users** and **API keys**, making access control and resource allocation easier for administrators.\\n\\n![api-keys](introduce-llmos/api-keys.png)\\n\\n### 7. Role-Based Access Control (RBAC) and Role Templates\\n\\nLLMOS offers enhanced **Role Templates** and **RBAC**, helping administrators assign permissions and manage security across teams and projects with ease.\\n\\n![role-templates](introduce-llmos/role-templates.png)\\n\\n### 8. Node Management\\n\\n**Node Management** is available directly through the LLMOS dashboard, allowing for better visibility and control over system resources, enhancing operational efficiency.\\n\\n![nodes](introduce-llmos/nodes.png)\\n![node-management](introduce-llmos/node-management.png)\\n\\n### 9. Bootstrap and Installation Support\\n\\nSetting up LLMOS has been simplified through easy-to-use **[installation script](https://llmos.1block.ai/docs/installation/)** and comprehensive **[bootstrap configurations](https://llmos.1block.ai/docs/installation/configurations)**, making it easy for users to get up and running.\\n\\n### 10. Easy Upgrades\\n\\nWith streamlined upgrade capabilities, LLMOS ensures that you can quickly adopt new features and improvements with minimal disruption.\\n\\n## LLMOS Use Cases\\n\\n- **AI Research & Development:** Simplify the management of LLMs and AI infrastructure, allowing researchers to focus on innovation rather than operational overhead.\\n- **Enterprise AI Solutions:** Streamline the deployment of AI applications with scalable infrastructure, making it easier to manage models, storage, and resources across multiple teams.\\n- **Data Science Workflows:** With notebook integration and powerful cluster computing, LLMOS is ideal for data scientists looking to run complex experiments at scale.\\n- **AI-Driven Products:** From chatbots to automated content generation, LLMOS simplifies the process of deploying LLM-based products that can serve millions of users and scale up horizontally.\\n\\n## Getting Started with LLMOS\\n\\nReady to get started with **LLMOS**? Our [detailed documentation](https://llmos.1block.ai/docs/) covers everything from installation to advanced features. Whether you\u2019re a developer, data scientist, or system administrator, you\u2019ll find LLMOS easy to set up and use, below is the quick-start guideline.\\n\\n:::note\\n  Make sure your nodes meet the [requirements](https://llmos.1block.ai/docs/installation/requirements) before proceeding.\\n:::\\n\\n##### Installation Script\\n\\nLLMOS can be installed to a bare-metal server or a virtual machine. To bootstrap a **new cluster**, follow the steps below:\\n```bash\\ncurl -sfL https://get-llmos.1block.ai | sh -s - --cluster-init --token mytoken\\n```\\n\\nTo monitor installation logs, run `journalctl -u llmos -f`.\\n\\nIf your environment requires internet access through a proxy, set the `HTTP_PROXY` and `HTTPS_PROXY` environment variables before running the installation script:\\n```bash\\nexport HTTP_PROXY=http://proxy.example.com:8080\\nexport HTTPS_PROXY=http://proxy.example.com:8080\\nexport NO_PROXY=127.0.0.0/8,10.0.0.0/8,172.16.0.0/12,192.168.0.0/16 # Replace the CIDRs with your own\\n```\\n\\n##### Getting Started\\n\\nAfter installing LLMOS, access the dashboard by navigating to `https://<server-ip>:8443` in your web browser.\\n\\n1. LLMOS will create a default `admin` user with a randomly generated password. To retrieve the password, run the following command on the **cluster-init** node:\\n\\n   ```shell\\n   kubectl get secret --namespace llmos-system llmos-bootstrap-passwd -o go-template=\'{{.data.password|base64decode}}{{\\"\\\\n\\"}}\'\\n   ```\\n    ![welcome-login](introduce-llmos/welcome-login.png)\\n1. Upon logging in, you will be redirected to the setup page. Configure the following:\\n  - Set a **new password** for the admin user (strong passwords are recommended).\\n  - Configure the **server URL** that all other nodes in your cluster will use to connect.\\n![welcome-config](introduce-llmos/welcome-config.png)\\n1. After setup, you will be redirected to the home page where you can start using LLMOS.\\n![home-page](introduce-llmos/home-page.png)\\n\\n## More Examples\\n\\nTo learn more about using LLMOS, explore the following resources:\\n\\n- [Chat with LLMOS Models](https://llmos.1block.ai/docs/user_guide/llm_management/serve)\\n- [Creating a Jupyter Notebook](https://llmos.1block.ai/docs/user_guide/llm_management/notebooks#create-a-notebook)\\n- [Creating a Machine Learning Cluster](https://llmos.1block.ai/docs/user_guide/ml_clusters)\\n\\n## Join Us\\n\\nWe are excited to build a community around the project. If you\'re interested, please join us on [Discord](https://discord.gg/5BnNqC5ccB) or participate in [Github Discussions](https://github.com/llmos-ai/llmos/discussions) to discuss or contribute the project. If you need to contact us, please reach out to us via [here](https://1block.ai/contact-us). We look forward to collaborating with you, thanks!"},{"id":"welcome","metadata":{"permalink":"/blog/welcome","editUrl":"https://github.com/oneblock-ai/1block.ai/tree/main/blog/index.md","source":"@site/blog/index.md","title":"Hello World @1Block.AI","description":"Why We Build 1Block.AI","date":"2024-01-01T00:00:00.000Z","tags":[{"inline":true,"label":"1Block.AI","permalink":"/blog/tags/1-block-ai"},{"inline":true,"label":"LLMOps","permalink":"/blog/tags/llm-ops"}],"readingTime":2.345,"hasTruncateMarker":false,"authors":[{"name":"Guangbo Chen","title":"Founder of 1BLOCK.AI","url":"https://github.com/guangbochen","email":"guangbo@1block.ai","socials":{"github":"https://github.com/guangbochen","linkedin":"https://www.linkedin.com/in/guangbo/"},"imageURL":"https://github.com/guangbochen.png","key":"guangbo","page":null}],"frontMatter":{"slug":"welcome","title":"Hello World @1Block.AI","authors":["guangbo"],"tags":["1Block.AI","LLMOps"],"date":"2024-01-01T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Introducing LLMOS","permalink":"/blog/introducing-llmos"}},"content":"```go\\nfunc main() {\\n    fmt.Println(\\"Hello World, @1Block.AI\\");\\n}\\n```\\n\\n## Why We Build 1Block.AI\\nWe believe that AGI (Artificial General Intelligence) is the next significant milestone in the human history. It will not only reshape how we live, work, and play but also revolutionize how we develop software.\\nWe are building **1Block.AI** to assist both developers and non-developers in unlocking the power of LLMs, allowing them to construct their own generative AI applications using a single, unified management platform.\\n\\n### What is 1Block.AI\\n\\n**1Block.AI** is an open-source, cloud-native LLMOps platform that fosters innovation in LLMs and generative AI applications. It is built on top of cutting-edge technologies such as [Kubernetes](https://kubernetes.io/), [Ray.io](https://ray.io/), [vLLM](https://docs.vllm.ai/en/latest/index.html), etc., and designed to be cloud-agnostic and ML framework agnostic.\\n\\nProjects like Ray(also KubeRay), and LangChain are excellent open-source projects for ML lifecycle management and can be served as the core components of the LLMOps. For instance, Ray offers powerful distributed computing capabilities and a comprehensive ML computing framework, forming a powerful ML foundation for the platform. However, they lack a unified solution for cluster management, multi-tenancy, cost control, data privacy protection, resource versioning, etc. \\nThese aspects need addressing in other components of the LLMOps platform. In essence, we believe a user-friendly LLMOps platform should encompass:\\n\\n- **Cost-effectiveness and Data Privacy**: The platform must be open-source, feature a distributed architecture, and support private deployment.\\n- **Easy to Use**: Provide a unified interface for developers and non-developers to implement complete life cycle management of Large Language Models(LLM) and generative AI applications.\\n    - **Exploratory Data Analysis (EDA)**: Iteratively explore, share, and prepare data for the machine learning lifecycle by creating reproducible, editable, and shareable datasets, tables, and visual charts.\\n    - **Model Registration and Management**: Allow users to upload, track, and manage versions of models and associate them with specific datasets and hyperparameters.\\n    - **Continuous Integration/Continuous Deployment (CI/CD)**: Ensure the continuous updating and deployment of models and AI agents, enabling them to respond promptly to new data and changes.\\n    - **Performance Monitoring and Logging**: Real-time monitoring of model performance, including metrics such as inference time, memory usage, and logging all interactions for auditing and fine-tuning.\\n    - **Automated Tuning and Optimization**: Automatically adjust and optimize models using tools to maintain their optimal performance in different environments.\\n- **No Vendor Lock-in**: Compatible with different cloud infrastructures and different ML frameworks(cloud-agnostic & ML-agnostic).\\n- **Scalability and Portability**: Supports serverless deployment, provides a unified solution for LLMs and generative AI applications to be deployed anywhere, from public cloud to on-premise servers.\\n- **Interoperability and maintainability**: customizable and extendable with cloud-native and ML ecosystems.\\n\\n![1block-ai-architecture](hello-world/1block-ai-architecture.png)\\n\\n## Join Us\\nWe are excited to build a community around the project. If you\'re interested, please join us on [Discord](https://discord.gg/5BnNqC5ccB) or participate in [Github Discussions](https://github.com/llmos-ai/llmos/discussions) to discuss or contribute the project. We look forward to collaborating with you. Merci!"}]}}')}}]);
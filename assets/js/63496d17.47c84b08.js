"use strict";(self.webpackChunk_1_block_ai=self.webpackChunk_1_block_ai||[]).push([[4201],{43570:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>a,contentTitle:()=>o,default:()=>h,frontMatter:()=>r,metadata:()=>l,toc:()=>d});var i=s(85893),t=s(11151);const r={slug:"introducing-llmos-v02",title:"LLMOS v0.2 - Simplify AI Management, Unlock GPU Potential",tags:["1Block.AI","AI Infrastructure"],authors:["guangbo"],date:new Date("2024-12-31T00:00:00.000Z"),hide_table_of_contents:!1},o=void 0,l={permalink:"/blog/introducing-llmos-v02",editUrl:"https://github.com/oneblock-ai/1block.ai/tree/main/blog/llmos-0.2-release.mdx",source:"@site/blog/llmos-0.2-release.mdx",title:"LLMOS v0.2 - Simplify AI Management, Unlock GPU Potential",description:"\ud83d\ude80 Introducing LLMOS v0.2",date:"2024-12-31T00:00:00.000Z",tags:[{inline:!0,label:"1Block.AI",permalink:"/blog/tags/1-block-ai"},{inline:!0,label:"AI Infrastructure",permalink:"/blog/tags/ai-infrastructure"}],readingTime:2.765,hasTruncateMarker:!1,authors:[{name:"Guangbo Chen",title:"Founder of 1BLOCK.AI",url:"https://github.com/guangbochen",email:"guangbo@1block.ai",socials:{github:"https://github.com/guangbochen",linkedin:"https://www.linkedin.com/in/guangbo/"},imageURL:"https://github.com/guangbochen.png",key:"guangbo",page:null}],frontMatter:{slug:"introducing-llmos-v02",title:"LLMOS v0.2 - Simplify AI Management, Unlock GPU Potential",tags:["1Block.AI","AI Infrastructure"],authors:["guangbo"],date:"2024-12-31T00:00:00.000Z",hide_table_of_contents:!1},unlisted:!1,nextItem:{title:"Introducing LLMOS",permalink:"/blog/introducing-llmos"}},a={authorsImageUrls:[void 0]},d=[{value:"<strong>\ud83d\ude80 Introducing LLMOS v0.2</strong>",id:"-introducing-llmos-v02",level:2},{value:"<strong>\ud83c\udf1f Key Features</strong>",id:"-key-features",level:2},{value:"<strong>1. More Efficient GPU Management</strong>",id:"1-more-efficient-gpu-management",level:3},{value:"<strong>2. Real-Time Monitoring and Alerts</strong>",id:"2-real-time-monitoring-and-alerts",level:3},{value:"<strong>\u26a1 Key Enhancements</strong>",id:"-key-enhancements",level:2},{value:"<strong>1. Faster Installation Experience</strong>",id:"1-faster-installation-experience",level:3},{value:"<strong>2. Expanded Model Service Sources</strong>",id:"2-expanded-model-service-sources",level:3},{value:"<strong>3. Optimized Workload Management</strong>",id:"3-optimized-workload-management",level:3},{value:"<strong>\ud83d\udee0 Updates and Fixes</strong>",id:"-updates-and-fixes",level:2},{value:"<strong>\ud83c\udf10 Ready to Experience?</strong>",id:"-ready-to-experience",level:2}];function c(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",hr:"hr",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.a)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h2,{id:"-introducing-llmos-v02",children:(0,i.jsx)(n.strong,{children:"\ud83d\ude80 Introducing LLMOS v0.2"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"LLMOS"})," is a cloud-native tool designed to ",(0,i.jsx)(n.strong,{children:"accelerate AI application development"})," and ",(0,i.jsx)(n.strong,{children:"simplify the management of large language models (LLMs)"}),". It supports deployment on both ",(0,i.jsx)(n.strong,{children:"public clouds"})," and ",(0,i.jsx)(n.strong,{children:"private GPU servers"}),", enabling you to easily deploy private AI models, scale machine learning workflows, and reduce the complexity of development and operations."]}),"\n",(0,i.jsxs)(n.p,{children:["With the increasing demand for GPU virtualization (vGPU) and resource utilization, the ",(0,i.jsx)(n.strong,{children:"v0.2"})," release prioritizes features like ",(0,i.jsx)(n.strong,{children:"vGPU management"}),", ",(0,i.jsx)(n.strong,{children:"cluster and GPU resource monitoring"}),", and ",(0,i.jsx)(n.strong,{children:"alerting"})," to maximize GPU management efficiency and utilization."]}),"\n",(0,i.jsx)(n.h2,{id:"-key-features",children:(0,i.jsx)(n.strong,{children:"\ud83c\udf1f Key Features"})}),"\n",(0,i.jsx)(n.h3,{id:"1-more-efficient-gpu-management",children:(0,i.jsx)(n.strong,{children:"1. More Efficient GPU Management"})}),"\n",(0,i.jsxs)(n.p,{children:["Introducing support for ",(0,i.jsx)(n.strong,{children:"NVIDIA Virtual GPU (vGPU)"}),", allowing you to choose between virtual or full GPUs based on your needs. This accelerates resource allocation and optimizes the utilization of GPU VRAM and CUDA cores."]}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"GPU Model"}),(0,i.jsx)(n.th,{children:"Support"}),(0,i.jsx)(n.th,{children:"Architecture"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"A100, A200"}),(0,i.jsx)(n.td,{children:"\u2705"}),(0,i.jsx)(n.td,{children:"NVIDIA Ampere"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"H100, H200"}),(0,i.jsx)(n.td,{children:"\u2705"}),(0,i.jsx)(n.td,{children:"NVIDIA Hopper"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Tesla T4/T4G"}),(0,i.jsx)(n.td,{children:"\u2705"}),(0,i.jsx)(n.td,{children:"NVIDIA Turing"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"30x/40x Series"}),(0,i.jsx)(n.td,{children:"\u2705"}),(0,i.jsx)(n.td,{children:"Ada Lovelace/Ampere"})]})]})]}),"\n",(0,i.jsxs)(n.p,{children:["\u2714 ",(0,i.jsx)(n.strong,{children:"Virtual GPU (vGPU)"}),": Optimize GPU utilization and scale workloads seamlessly."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.img,{alt:"model-service-create",src:s(94530).Z+"",width:"3042",height:"1372"}),"\n",(0,i.jsx)(n.img,{alt:"model-service-vram",src:s(28733).Z+"",width:"1642",height:"1002"})]}),"\n",(0,i.jsxs)(n.p,{children:["\u2714 ",(0,i.jsx)(n.strong,{children:"GPU Management Interface"}),": Intuitively view GPU details and monitor resources in real time."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.img,{alt:"gpu-device",src:s(14521).Z+"",width:"3178",height:"1470"}),"\n",(0,i.jsx)(n.img,{alt:"gpu-device-metrics",src:s(43544).Z+"",width:"3250",height:"1700"})]}),"\n",(0,i.jsxs)(n.p,{children:["\ud83d\udc49 ",(0,i.jsx)(n.a,{href:"https://llmos.1block.ai/docs/user_guide/gpu_management/enable-gpu-stack/",children:"Learn More"})]}),"\n",(0,i.jsx)(n.h3,{id:"2-real-time-monitoring-and-alerts",children:(0,i.jsx)(n.strong,{children:"2. Real-Time Monitoring and Alerts"})}),"\n",(0,i.jsxs)(n.p,{children:["Enable GPU and cluster monitoring with a single click using preconfigured ",(0,i.jsx)(n.strong,{children:"Grafana dashboards and Prometheus alerts"}),". Track performance metrics in real time to ensure stable workload operations."]}),"\n",(0,i.jsxs)(n.p,{children:["\u2714 ",(0,i.jsx)(n.strong,{children:"Real-Time Monitoring"}),": Stay informed about cluster and GPU status."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"cluster-gpu-metrics",src:s(62725).Z+"",width:"3390",height:"1696"})}),"\n",(0,i.jsxs)(n.p,{children:["\u2714 ",(0,i.jsx)(n.strong,{children:"Intelligent Alerts"}),": Predefined rules to reduce risks of failures and downtime."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"monitoring-rules",src:s(71621).Z+"",width:"3146",height:"1368"})}),"\n",(0,i.jsxs)(n.p,{children:["\u2714 ",(0,i.jsx)(n.strong,{children:"Pause and Resume Workloads"}),": Release idle resources to enhance efficiency."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"workload-actions",src:s(71076).Z+"",width:"3160",height:"1072"})}),"\n",(0,i.jsxs)(n.p,{children:["\ud83d\udc49 ",(0,i.jsx)(n.a,{href:"https://llmos.1block.ai/docs/user_guide/monitoring/monitoring-management/",children:"Learn More"})]}),"\n",(0,i.jsx)(n.h2,{id:"-key-enhancements",children:(0,i.jsx)(n.strong,{children:"\u26a1 Key Enhancements"})}),"\n",(0,i.jsx)(n.h3,{id:"1-faster-installation-experience",children:(0,i.jsx)(n.strong,{children:"1. Faster Installation Experience"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["For CN users, you can accelerate installation with ",(0,i.jsx)(n.code,{children:"--mirror cn"}),"."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"curl -sfL https://get-llmos.1block.ai | sh -s - --cluster-init --token mytoken --mirror cn\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["For restricted network and air-gap environments, use configurations like ",(0,i.jsx)(n.code,{children:"globalSystemImageRegistry"})," or ",(0,i.jsx)(n.code,{children:"registries"})," to integrate private image registries, accelerating and simplifying the installation process."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"2-expanded-model-service-sources",children:(0,i.jsx)(n.strong,{children:"2. Expanded Model Service Sources"})}),"\n",(0,i.jsxs)(n.p,{children:["Support loading AI models from ",(0,i.jsx)(n.a,{href:"https://huggingface.co/models",children:"HuggingFace"}),", ",(0,i.jsx)(n.a,{href:"https://modelscope.cn/models",children:"ModelScope"}),", or local paths, offering more flexibility in model deployment for your projects."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"model-service-sources",src:s(46049).Z+"",width:"3156",height:"1126"})}),"\n",(0,i.jsx)(n.h3,{id:"3-optimized-workload-management",children:(0,i.jsx)(n.strong,{children:"3. Optimized Workload Management"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Automatic Volume Cleanup"}),": Automatically release storage resources after workload deletion, simplifying management."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Notebook Optimization"}),": Added support for Jupyter Pipeline images and i18n localization(e.g., Chinese) patches.\n",(0,i.jsx)(n.img,{alt:"notebook-pipeline",src:s(25228).Z+"",width:"3838",height:"1868"})]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Node-Level GPU Metrics Optimization"}),": Gain detailed overviews of GPU resources to enable fine-grained management.\n",(0,i.jsx)(n.img,{alt:"node-metrics",src:s(11398).Z+"",width:"3182",height:"858"})]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Enhanced Model Token Metrics"}),": View real-time model token usage and response speeds to optimize resource planning and task execution of model services.\n",(0,i.jsx)(n.img,{alt:"token-metrics",src:s(14558).Z+"",width:"3238",height:"1746"})]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"-updates-and-fixes",children:(0,i.jsx)(n.strong,{children:"\ud83d\udee0 Updates and Fixes"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Dependency Updates"}),": System dependencies have been updated to improve performance, security, and compatibility:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Rook Ceph and Ceph cluster upgraded to ",(0,i.jsx)(n.code,{children:"v1.15.7"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["Snapshot Controller upgraded to ",(0,i.jsx)(n.code,{children:"v8.2.0"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["Upgrade Controller upgraded to ",(0,i.jsx)(n.code,{children:"v0.14.2"}),"."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Key Bug Fixes"}),":","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Model Service Parameter Issues"}),": Fixed to allow seamless parameter updates."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Label Nil Exception"}),": Custom addon will no longer experience label ",(0,i.jsx)(n.code,{children:"nil"})," exception."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"User Permission Optimization"}),": Removed unnecessary node permissions for regular users, enhancing security."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"-ready-to-experience",children:(0,i.jsx)(n.strong,{children:"\ud83c\udf10 Ready to Experience?"})}),"\n",(0,i.jsxs)(n.p,{children:["Visit the ",(0,i.jsx)(n.a,{href:"https://llmos.1block.ai/docs/",children:"documentation"})," to learn more. Upgrade to LLMOS v0.2 today and experience the future of AI management!"]}),"\n",(0,i.jsxs)(n.p,{children:["\ud83d\ude80 ",(0,i.jsx)(n.strong,{children:"Upgrade Now!"})]})]})}function h(e={}){const{wrapper:n}={...(0,t.a)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},62725:(e,n,s)=>{s.d(n,{Z:()=>i});const i=s.p+"assets/images/cluster-gpu-metrics-64fc8320e79a837a9cbf181817de1eea.png"},43544:(e,n,s)=>{s.d(n,{Z:()=>i});const i=s.p+"assets/images/gpu-device-metrics-224ebee35965b31073dc4728eb1edfde.png"},14521:(e,n,s)=>{s.d(n,{Z:()=>i});const i=s.p+"assets/images/gpu-device-f586f480b657a8f32d87a36efb20ce6d.png"},94530:(e,n,s)=>{s.d(n,{Z:()=>i});const i=s.p+"assets/images/model-service-create-ca6710ff50620658996d45540240caaf.png"},46049:(e,n,s)=>{s.d(n,{Z:()=>i});const i=s.p+"assets/images/model-service-sources-229b654228aa0d1f85e5dab4d5fbf69d.png"},28733:(e,n,s)=>{s.d(n,{Z:()=>i});const i=s.p+"assets/images/model-service-vram-d3bd41a1267878ecdc30b222db493a23.png"},71621:(e,n,s)=>{s.d(n,{Z:()=>i});const i=s.p+"assets/images/monitoring-rules-db1f22e647b71c882ccf6a5c9ae52239.png"},11398:(e,n,s)=>{s.d(n,{Z:()=>i});const i=s.p+"assets/images/node-metrics-ca8e8d7e3e000cd48bd2fa24a704942a.png"},25228:(e,n,s)=>{s.d(n,{Z:()=>i});const i=s.p+"assets/images/notebook-pipeline-93b4caa6676b71c23c6ff58aab227a9c.png"},14558:(e,n,s)=>{s.d(n,{Z:()=>i});const i=s.p+"assets/images/token-metrics-e336a79b0cb8fd32967e0007bd12bc0c.png"},71076:(e,n,s)=>{s.d(n,{Z:()=>i});const i=s.p+"assets/images/workload-actions-bd5794a038a4f51467da36055808e7c7.png"},11151:(e,n,s)=>{s.d(n,{Z:()=>l,a:()=>o});var i=s(67294);const t={},r=i.createContext(t);function o(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);